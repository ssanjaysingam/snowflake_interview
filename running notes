>> Cluster Key
Use the system function, SYSTEM$CLUSTERING_INFORMATION, to calculate clustering details, including clustering depth, for a given table.

Clustering key consists of one or more table columns/expressions, which can be of any data type, except GEOGRAPHY, VARIANT, OBJECT, or ARRAY. 
A clustering key can contain any of the following:
Base columns.
Expressions on base columns.
Expressions on paths in VARIANT columns.

An existing cluster key is copied when a table is created using clone but not copied when table created using CTAS or like command.

To suspend/resuming Automatic Clustering for a table:
alter table t1 suspend recluster;
alter table t1 resume recluster;

Viewing automatic clustering history:
AUTOMATIC_CLUSTERING_HISTORY
Snowsight: Admin > Usage

For most tables, Snowflake recommends a maximum of 3 or 4 columns (or expressions) per key. Adding more than 3-4 columns tends to increase costs more than benefits.

If you are defining a multi-column clustering key for a table, the order in which the columns are specified in the CLUSTER BY clause is important. As a general rule, 
Snowflake recommends ordering the columns from lowest cardinality to highest cardinality.
When clustering on a text field, the cluster key metadata only tracks the first 6 characters. For string fields that need more characters to get unique values, 
cluster on the HASH of the column instead of the column itself.
For example, if all values in the event_type column begin with event_, you should cluster by HASH(event_type)

>> Show Functions:
Lists all the native (i.e. system-defined/built-in) scalar functions provided by Snowflake, 
as well as any user-defined functions (UDFs) or external functions that have been created for your account.

The command does not require a running warehouse to execute.
The command returns a maximum of 10K records for the specified object type, as dictated by the access privileges 
for the role used to execute the command; any records above the 10K limit are not returned, even with a filter applied.
To view results for which more than 10K records exist, query the corresponding view (if one exists) in the Snowflake Information Schema.

>> Constraints:
Snowflake supports the following constraint types from the ANSI SQL standard:
UNIQUE, PRIMARY KEY, FOREIGN KEY, NOT NULL

Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.

>> Stages
To stage files to a table stage, list the files, query them on the stage, or drop them, you must be the 
table owner (have the role with the OWNERSHIP privilege on the table).

>>INFER_SCHEMA
Automatically detects the file metadata schema in a set of staged data files that contain semi-structured data and retrieves the column definitions.
This feature is currently limited to Apache Parquet, Apache Avro, and ORC files.

>> GENERATE_COLUMN_DESCRIPTION
Generates a list of columns from a set of staged files that contain semi-structured data using the INFER_SCHEMA function output.
-- Create a file format that sets the file type as Parquet.
create file format my_parquet_format
  type = parquet;

-- Query the GENERATE_COLUMN_DESCRIPTION function.
select generate_column_description(array_agg(object_construct(*)), 'table') as columns
  from table (
    infer_schema(
      location=>'@mystage',
      file_format=>'my_parquet_format'
    )
  );
  
>> Loading
The wizard is only intended for loading small numbers of files of limited size (up to 50 MB).
For loading larger files or large numbers of files, we recommend using the Snowflake client, SnowSQL

>>Search Optimization Service
The search optimization service can significantly improve the performance of point lookup queries.
Search optimization is a table-level property and applies to all columns with supported data types
A maintenance service that runs in the background is responsible for creating and maintaining the search access path.
The search optimization service speeds only equality searches.

You must have OWNERSHIP privilege on the table.
You must have ADD SEARCH OPTIMIZATION privilege on the schema that contains the table.

Use APPROX_COUNT_DISTINCT to get the approximate number of distinct values.
Data Types Supported By the Search Optimization Service

The search optimization service currently supports equality predicate and IN list predicate searches for the following data types:
Fixed-point numbers (e.g. INTEGER, NUMERIC).
DATE, TIME, and TIMESTAMP.
VARCHAR.
BINARY.

ALTER TABLE [IF EXISTS] <table_name> ADD/DROP SEARCH OPTIMIZATION;


>> Shares:

If you plan to securely share data with data consumers across different regions or cloud platforms, note that currently,
replicating a primary database is blocked if one or more external tables exist in the database.

A new object created in a database in a share is not automatically available to consumers.
To make the object available to consumers, you must use the GRANT <privilege> â€¦ TO SHARE command to explicitly add the object to the share.

Do not include secure objects that use the CURRENT_USER or CURRENT_ROLE functions in their definition.

Enabling Data Consumers to Create Table Streams on Shared Tables
In order for data consumers to create streams on shared tables or secure views, you must enable change tracking 
on the shared tables or the underlying tables for a shared view.
In addition, the data retention period should be extended for the tables.

If you have a Business Critical account and are sharing data with consumer accounts
Snowflake supports sharing sensitive data with non-Business Critical accounts (disabled by default), but does not encourage doing so.
To ensure compliance with HIPAA and HITRUST requirements, Snowflake does not allow HIPAA accounts to share data with non-HIPAA accounts.
If you are using Tri-Secret Secure data protection, note that Snowflake treats data access from consumer accounts as if the access occurred
from within your own account.

SHOW GRANTS OF SHARE lists all accounts that have created a database from the share. 
If no accounts have created a database from the share, the results are empty.
